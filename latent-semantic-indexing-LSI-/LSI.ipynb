{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d16cc99f-9c77-4247-9a67-29f7a1719c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Load Dataset\n",
    "documents_list = []\n",
    "with open( os.path.join(\"survey.csv\") ,\"r\") as fin:\n",
    "    for line in fin.readlines():\n",
    "        text = line.strip()\n",
    "        documents_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eda052de-1e49-4394-993a-e78d7ef87c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize regex tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Vectorize document using TF-IDF\n",
    "tfidf = TfidfVectorizer(lowercase=True,\n",
    "                        stop_words='english',\n",
    "                        ngram_range = (1,10),\n",
    "                        tokenizer = tokenizer.tokenize)\n",
    "\n",
    "# Fit and Transform the documents\n",
    "train_data = tfidf.fit_transform(documents_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32b9ebdb-5b93-4700-b354-b890921d7650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of topics or components\n",
    "num_components=10\n",
    "\n",
    "# Create SVD object\n",
    "lsa = TruncatedSVD(n_components=num_components, n_iter=100, random_state=42)\n",
    "\n",
    "# Fit SVD model on data\n",
    "lsa.fit_transform(train_data)\n",
    "\n",
    "# Get Singular values and Components \n",
    "Sigma = lsa.singular_values_ \n",
    "V_transpose = lsa.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "358043b6-a8a8-4734-bcf5-ba5d6b03c281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:  ['15', '5', '15 5', '11', '2020']\n",
      "Topic 1:  ['metropolitan', '12e 15 5 current events damage typhoon goni 2 5', '15 5 current events damage typhoon goni 2 5', '15 5 current events damage typhoon goni 2 5 74e', '15 ph manila_typhoon_goni_damage']\n",
      "Topic 2:  ['68e', '68e 15', '15 5 current events damage typhoon goni 2 4 68e', '15 ph bicol_typhoon_goni_damage', '15 ph bicol_typhoon_goni_damage 5']\n",
      "Topic 3:  ['caused severe winds don', 'caused severe winds don t', 'caused severe winds don t know', 'caused severe winds don t know https', 'caused severe winds don t know https storage']\n",
      "Topic 4:  ['04e 15 diamondhead 3 diamondhead male 26', '04e 15 diamondhead 3 diamondhead male 26 35', '04e 15 diamondhead 3 diamondhead male 26 35 years', '04e 15 diamondhead 3 diamondhead male 26 35 years old', '15 diamondhead 3 diamondhead male 26']\n",
      "Topic 5:  ['26 35 years old rural', '26 35 years old rural afford', '26 35 years old rural afford food', '35 years old rural', '35 years old rural afford']\n",
      "Topic 6:  ['area comfortably', 'area comfortably afford', 'area comfortably afford food', 'area comfortably afford food clothes', 'area comfortably afford food clothes furniture']\n",
      "Topic 7:  ['3 diamondhead female 16 25 years old rural afford', '3 diamondhead female 16 25 years old rural afford food', 'diamondhead 3 diamondhead female 16 25 years old rural afford', 'diamondhead female 16 25 years old rural afford', 'diamondhead female 16 25 years old rural afford food']\n",
      "Topic 8:  ['afford food clothes', 'afford food clothes furniture', 'afford food clothes furniture savings', 'clothes furniture', 'clothes furniture savings']\n",
      "Topic 9:  ['36 45', '36 45 years', '36 45 years old', '45 years', '45 years old']\n"
     ]
    }
   ],
   "source": [
    "# Print the topics with their terms\n",
    "terms = tfidf.get_feature_names()\n",
    "\n",
    "for index, component in enumerate(lsa.components_):\n",
    "    zipped = zip(terms, component)\n",
    "    top_terms_key=sorted(zipped, key = lambda t: t[1], reverse=True)[:5]\n",
    "    top_terms_list=list(dict(top_terms_key).keys())\n",
    "    print(\"Topic \"+str(index)+\": \",top_terms_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
